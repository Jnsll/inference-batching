{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from importlib import reload\n",
    "from subprocess import Popen, PIPE\n",
    "from threading import Thread\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from torch.nn import Module\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU Monitor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class GPUMonitor(Thread):\n",
    "    def __init__(self, delay):\n",
    "        super(GPUMonitor, self).__init__()\n",
    "        self.delay = delay\n",
    "        self.power_readings = []\n",
    "        self.running = True\n",
    "        self.start()\n",
    "\n",
    "    def run(self):\n",
    "        while self.running:\n",
    "            try:\n",
    "                p = Popen('nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits'.split(' '), stdout=PIPE)\n",
    "                stdout, stderror = p.communicate()\n",
    "                self.power_readings.append(float(stdout.strip()))\n",
    "                p.terminate()\n",
    "            except:\n",
    "                logging.error('Something went wrong while retrieving GPU readings...')\n",
    "            time.sleep(self.delay)\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "\n",
    "    def reset_energy(self):\n",
    "        self.power_readings = []\n",
    "\n",
    "    def get_power_average(self):\n",
    "        return np.mean(self.power_readings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])\n",
    "with open('image_net_classes.txt') as file:\n",
    "    classes = [line.strip().split(', ')[1] for line in file.readlines()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def infer(model: Module, images, use_gpu=True, verbose=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if use_gpu:\n",
    "            model.cuda()\n",
    "        images_t = [transform(im) for im in images]\n",
    "        batch = torch.cat([tensor for tensor in [torch.unsqueeze(im_t, 0) for im_t in images_t]])\n",
    "        if use_gpu:\n",
    "            out = model(batch.cuda())\n",
    "        else:\n",
    "            out = model(batch)\n",
    "\n",
    "    for prediction in out:\n",
    "        prediction = prediction.cpu()\n",
    "        _, indices = torch.sort(prediction, descending=True)\n",
    "        percentages = [(torch.nn.functional.softmax(prediction, dim=0)[class_index] * 100).item() for class_index in\n",
    "                       indices[:5]]\n",
    "        if verbose:\n",
    "            logging.info(f'Rank\\tInferred class\\tProbability(%)')\n",
    "            for idx, class_index in enumerate(indices[:5]):\n",
    "                logging.info(f'#{idx}\\t\\t{classes[class_index]}\\t{percentages[idx]}')\n",
    "            logging.info('-----------------------------------------')\n",
    "\n",
    "def run_experiment(model_, input_images_, batch_size_, gpu_monitor_):\n",
    "    gpu_monitor_.reset_energy()\n",
    "    t_0 = time.perf_counter()\n",
    "    for i in tqdm(range(0, len(input_images_), batch_size_)):\n",
    "        infer(model_, input_images_[i:i+batch_size_], use_gpu=True)\n",
    "    return time.perf_counter() - t_0, gpu_monitor.get_power_average()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:25<00:00, 40.45it/s]\n",
      "01:20:44 INFO: Single inference stats: 82.98312101910827 watts for 25.314886432000094 s\n",
      "100%|██████████| 128/128 [00:10<00:00, 11.66it/s]\n",
      "01:20:55 INFO: Batch inference stats: 85.79307692307692 watts for 10.97552584999994 s\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('img/dog.jpg')\n",
    "img2 = Image.open('img/strawberries.jpg')\n",
    "img3 = Image.open('img/bald_eagle.jpg')\n",
    "gpu_monitor = GPUMonitor(0.1)\n",
    "model = models.resnet101(pretrained=True)\n",
    "input_images = [img for _ in range(1024)]\n",
    "\n",
    "# Single inference\n",
    "t, P = run_experiment(model, input_images, 1, gpu_monitor)\n",
    "logging.info(f'Single inference stats: {P} watts for {t} s')\n",
    "\n",
    "# Batch inference\n",
    "t, P = run_experiment(model, input_images, 8, gpu_monitor)\n",
    "logging.info(f'Batch inference stats: {P} watts for {t} s')\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gpu_monitor.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}